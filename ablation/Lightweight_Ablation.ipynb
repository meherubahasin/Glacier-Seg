{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c23baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "PyTorch: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Ti\n",
      "mamba_ssm found: True\n",
      "mamba_model found: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, torch\n",
    "print('Python:', sys.version)\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Check presence of mamba_ssm (optional) and mamba_model (required)\n",
    "try:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.find_spec('mamba_ssm')\n",
    "    print('mamba_ssm found:', spec is not None)\n",
    "except Exception as e:\n",
    "    print('mamba_ssm check error:', e)\n",
    "\n",
    "try:\n",
    "    spec2 = importlib.util.find_spec('mamba_model')\n",
    "    print('mamba_model found:', spec2 is not None)\n",
    "except Exception as e:\n",
    "    print('mamba_model check error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd3d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1369e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PATCH_SIZE = 256\n",
    "TARGET_SIZE = (256, 256)\n",
    "LABEL_KEY = 'outlines'\n",
    "MODALITIES_3 = ['dem', 'optical', 'bright_dark_outlines']\n",
    "CHANNEL_INFO_3 = {'dem': 2, 'optical': 6, 'bright_dark_outlines': 3}\n",
    "\n",
    "def normalize(arr):\n",
    "    arr = arr.astype(np.float32)\n",
    "    return (arr - arr.mean()) / (arr.std() + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2e84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_patch(img, label):\n",
    "    if random.random() < 0.5:\n",
    "        img = np.flip(img, axis=0)\n",
    "        label = np.flip(label, axis=0)\n",
    "    if random.random() < 0.5:\n",
    "        img = np.flip(img, axis=1)\n",
    "        label = np.flip(label, axis=1)\n",
    "    return img, label\n",
    "\n",
    "class GlacierHDF5PatchDataset3(Dataset):\n",
    "    def __init__(self, hdf5_file_path, patch_size=PATCH_SIZE, target_size=TARGET_SIZE, length = 600):\n",
    "        self.hdf5 = h5py.File(hdf5_file_path, 'r')\n",
    "        self.tiles = [name for name in self.hdf5.keys() if all(m in self.hdf5[name] for m in MODALITIES_3)]\n",
    "        self.patch_size = patch_size\n",
    "        self.target_size = target_size\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile_name = random.choice(self.tiles)\n",
    "        tile = self.hdf5[tile_name]\n",
    "        h, w = tile[MODALITIES_3[0]].shape[:2]\n",
    "        y = random.randint(0, h - self.patch_size)\n",
    "        x = random.randint(0, w - self.patch_size)\n",
    "\n",
    "        input_channels = []\n",
    "        for key in MODALITIES_3:\n",
    "            arr = tile[key][y:y+self.patch_size, x:x+self.patch_size, :]\n",
    "            arr = normalize(arr)\n",
    "            input_channels.append(arr)\n",
    "        input_patch = np.concatenate(input_channels, axis=2)\n",
    "        label = tile[LABEL_KEY][y:y+self.patch_size, x:x+self.patch_size]\n",
    "        if label.ndim == 3:\n",
    "            label = label[:, :, 0] if label.shape[2] == 1 else np.argmax(label, axis=2)\n",
    "        input_patch, label = augment_patch(input_patch, label)\n",
    "        input_tensor = torch.tensor(np.ascontiguousarray(input_patch)).permute(2, 0, 1).float()\n",
    "        label_tensor = torch.tensor(np.ascontiguousarray(label), dtype=torch.long)\n",
    "        return input_tensor, label_tensor\n",
    "\n",
    "    def close(self):\n",
    "        self.hdf5.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3f1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    jaccard_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def segmentation_metrics(y_true, y_pred, num_classes=2):\n",
    "    y_true = y_true.ravel()\n",
    "    y_pred = y_pred.ravel()\n",
    "\n",
    "    labels = list(range(num_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    # Safe scoring: missing classes won't crash\n",
    "    per_class_iou  = jaccard_score (y_true, y_pred, average=None, labels=labels, zero_division=0)\n",
    "    mean_iou       = jaccard_score (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    per_class_dice = f1_score      (y_true, y_pred, average=None, labels=labels, zero_division=0)\n",
    "    mean_dice      = f1_score      (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    precision      = precision_score(y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    recall         = recall_score   (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    pixel_acc      = accuracy_score (y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"pixel_acc\": pixel_acc,\n",
    "        \"mean_iou\": mean_iou,\n",
    "        \"mean_dice\": mean_dice,\n",
    "        \"per_class_iou\": per_class_iou,     # np.ndarray, length=num_classes\n",
    "        \"per_class_dice\": per_class_dice,   # np.ndarray, length=num_classes\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"confusion_matrix\": cm              # shape: (num_classes, num_classes)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3563a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early-stop when monitored metric doesn't improve after `patience` epochs.\n",
    "    mode='max' for metrics like mIoU; set delta to require minimal improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, mode='max', min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.best = None\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, current):\n",
    "        if self.best is None:\n",
    "            self.best = current\n",
    "            return False\n",
    "\n",
    "        improved = (current > self.best + self.min_delta) if self.mode == 'max' else (current < self.best - self.min_delta)\n",
    "        if improved:\n",
    "            self.best = current\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        return self.should_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c59e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(model, opt_cfg=None):\n",
    "    opt_cfg = opt_cfg or {\"name\": \"AdamW\", \"lr\": 3e-6, \"weight_decay\": 1e-4}\n",
    "    name = opt_cfg.get(\"name\", \"AdamW\").lower()\n",
    "    lr = opt_cfg.get(\"lr\", 3e-6)\n",
    "    wd = opt_cfg.get(\"weight_decay\", 1e-4)\n",
    "    momentum = opt_cfg.get(\"momentum\", 0.9)\n",
    "\n",
    "    if name == \"sgd\":\n",
    "        return optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum, nesterov=True)\n",
    "    elif name == \"adam\":\n",
    "        return optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    else:\n",
    "        return optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "def build_scheduler(optimizer, sch_cfg=None):\n",
    "    \"\"\"\n",
    "    Default: ReduceLROnPlateau on val mIoU (mode='max').\n",
    "    If you want cosine/step later, we can expand this switch.\n",
    "    \"\"\"\n",
    "    sch_cfg = sch_cfg or {\"name\": \"ReduceLROnPlateau\", \"factor\": 0.5, \"patience\": 5, \"threshold\": 1e-4, \"min_lr\": 1e-7}\n",
    "    name = sch_cfg.get(\"name\", \"ReduceLROnPlateau\").lower()\n",
    "\n",
    "    if name == \"reducelronplateau\":\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"max\",\n",
    "            factor=sch_cfg.get(\"factor\", 0.5),\n",
    "            patience=sch_cfg.get(\"patience\", 5),\n",
    "            threshold=sch_cfg.get(\"threshold\", 1e-4),\n",
    "            cooldown=sch_cfg.get(\"cooldown\", 0),\n",
    "            min_lr=sch_cfg.get(\"min_lr\", 1e-7)\n",
    "        )\n",
    "    elif name == \"cosineannealing\":\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=sch_cfg.get(\"T_max\", 50), eta_min=sch_cfg.get(\"min_lr\", 1e-7)\n",
    "        )\n",
    "    elif name == \"steplr\":\n",
    "        return optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=sch_cfg.get(\"step_size\", 30), gamma=sch_cfg.get(\"gamma\", 0.1)\n",
    "        )\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9eb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss/len(loader)\n",
    "\n",
    "def eval_epoch(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.numel()\n",
    "    return total_loss/len(loader), correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00769abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/home/goblin/dataset/20230905_train_global_ps384.hdf5\"\n",
    "VAL_PATH = \"/home/goblin/dataset/20230905_val_global_ps384.hdf5\"\n",
    "TEST_PATH = \"/home/goblin/dataset/20230905_test_global_ps384.hdf5\"\n",
    "WEIGHT_DIR = \"weights/NIRD_Config\"\n",
    "os.makedirs(WEIGHT_DIR, exist_ok=True)\n",
    "\n",
    "dataset_train = GlacierHDF5PatchDataset3(TRAIN_PATH, length=2000)\n",
    "dataset_val = GlacierHDF5PatchDataset3(VAL_PATH, length = 500)\n",
    "dataset_test = GlacierHDF5PatchDataset3(TEST_PATH, length = 800)\n",
    "train_loader= DataLoader(dataset_train, batch_size=30, shuffle=True)\n",
    "dev_loader = DataLoader(dataset_val, batch_size=30, shuffle=False)\n",
    "dev_loader = DataLoader(dataset_test, batch_size=30, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb877715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cpu\n",
      "[ERROR] thop profiling failed: Pointer argument (at 0) cannot be accessed from Triton (cpu tensor?)\n",
      "[ERROR] torchinfo summary failed: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [OverlapPatchEmbedInvo: 4, Involution2D: 5, AvgPool2d: 6, Conv2d: 6, ReLU: 6, Conv2d: 6, Conv2d: 5, BatchNorm2d: 5]\n",
      "[ERROR] Analysis failed: Pointer argument (at 0) cannot be accessed from Triton (cpu tensor?)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from thop import profile\n",
    "from torchinfo import summary\n",
    "\n",
    "def analyze_model(model, input_size=(1, 11, 256, 256), device=None):\n",
    "    # --- Device selection ---\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "    # --- Move model and input to device ---\n",
    "    model = model.to(device)\n",
    "    dummy_input = torch.randn(*input_size).to(device)\n",
    "\n",
    "    # --- Verify device consistency ---\n",
    "    if next(model.parameters()).device != dummy_input.device:\n",
    "        raise RuntimeError(f\"Model and input device mismatch: model on {next(model.parameters()).device}, input on {dummy_input.device}\")\n",
    "\n",
    "    # --- FLOPs & MACs ---\n",
    "    try:\n",
    "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "        flops = 2 * macs  # 1 MAC = 2 FLOPs\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] thop profiling failed: {e}\")\n",
    "        macs, params, flops = 0, 0, 0  # Fallback values\n",
    "\n",
    "    # --- Torchinfo summary ---\n",
    "    try:\n",
    "        print(summary(model, input_size=input_size, device=device))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] torchinfo summary failed: {e}\")\n",
    "\n",
    "    # --- Inference time ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        for _ in range(5):\n",
    "            _ = model(dummy_input)\n",
    "        torch.cuda.synchronize() if device.startswith(\"cuda\") else None  # Sync for GPU\n",
    "        start = time.time()\n",
    "        for _ in range(20):\n",
    "            _ = model(dummy_input)\n",
    "        torch.cuda.synchronize() if device.startswith(\"cuda\") else None  # Sync for GPU\n",
    "        end = time.time()\n",
    "    avg_time = (end - start) / 20 * 1000  # Convert to ms/sample\n",
    "\n",
    "    return {\n",
    "        \"device\": device,\n",
    "        \"params\": params,\n",
    "        \"macs\": macs / 1e6,  # Convert to millions\n",
    "        \"flops\": flops / 1e6,  # Convert to millions\n",
    "        \"avg_inference_time_ms\": avg_time\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    model = SegFormer(num_classes=2, in_chans=11)  # Ensure SegFormer is defined\n",
    "    stats = analyze_model(model, input_size=(1, 11, 256, 256), device=\"cpu\")\n",
    "    print(stats)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e707d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Mamba-Involution-B0-default', 'mixer_type': 'Mamba', 'stem_type': 'Involution', 'backbone_variant': 'mit_b0', 'embed_dims': [16, 32, 64, 128], 'depths': [1, 1, 1, 1], 'use_invo_stages': (True, True, True, True)}, {'name': 'Mamba-Convolution-B0-default', 'mixer_type': 'Mamba', 'stem_type': 'Convolution', 'backbone_variant': 'mit_b0', 'embed_dims': [16, 32, 64, 128], 'depths': [1, 1, 1, 1], 'use_invo_stages': (False, False, False, False)}, {'name': 'Mamba-Involution-B0-shallow', 'mixer_type': 'Mamba', 'stem_type': 'Involution', 'backbone_variant': 'mit_b0', 'embed_dims': [16, 32, 64, 128], 'depths': [1, 1, 1, 1], 'use_invo_stages': (True, True, True, True)}, {'name': 'Mamba-Involution-B0-deep', 'mixer_type': 'Mamba', 'stem_type': 'Involution', 'backbone_variant': 'mit_b0', 'embed_dims': [16, 32, 64, 128], 'depths': [2, 2, 2, 2], 'use_invo_stages': (True, True, True, True)}, {'name': 'Mamba-Involution-B0-wider', 'mixer_type': 'Mamba', 'stem_type': 'Involution', 'backbone_variant': 'mit_b0', 'embed_dims': [32, 64, 128, 256], 'depths': [1, 1, 1, 1], 'use_invo_stages': (True, True, True, True)}, {'name': 'Mamba-Convolution-B0-wider', 'mixer_type': 'Mamba', 'stem_type': 'Convolution', 'backbone_variant': 'mit_b0', 'embed_dims': [32, 64, 128, 256], 'depths': [1, 1, 1, 1], 'use_invo_stages': (False, False, False, False)}]\n"
     ]
    }
   ],
   "source": [
    "model_configs = [\n",
    "    {\n",
    "        'name': 'Mamba-Involution-B0-default',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Involution',\n",
    "        'backbone_variant': 'mit_b0',\n",
    "        'embed_dims': [16, 32, 64, 128],\n",
    "        'depths': [1, 1, 1, 1],\n",
    "        'use_invo_stages': (True, True, True, True) # Use Involution for all stages with Involution stem\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mamba-Convolution-B0-default',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Convolution',\n",
    "        'backbone_variant': 'mit_b0',\n",
    "        'embed_dims': [16, 32, 64, 128],\n",
    "        'depths': [1, 1, 1, 1],\n",
    "        'use_invo_stages': (False, False, False, False) # Use Convolution for all stages with Convolution stem\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mamba-Involution-B0-shallow',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Involution',\n",
    "        'backbone_variant': 'mit_b0', # Still based on B0 structure\n",
    "        'embed_dims': [16, 32, 64, 128],\n",
    "        'depths': [1, 1, 1, 1], # Example of a slightly shallower variant\n",
    "        'use_invo_stages': (True, True, True, True)\n",
    "    },\n",
    "     {\n",
    "        'name': 'Mamba-Involution-B0-deep',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Involution',\n",
    "        'backbone_variant': 'mit_b0', # Still based on B0 structure\n",
    "        'embed_dims': [16, 32, 64, 128],\n",
    "        'depths': [2, 2, 2, 2], # Example of a slightly deeper variant\n",
    "        'use_invo_stages': (True, True, True, True)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mamba-Involution-B0-wider',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Involution',\n",
    "        'backbone_variant': 'mit_b0', # Still based on B0 structure\n",
    "        'embed_dims': [32, 64, 128, 256], # Example of a wider variant\n",
    "        'depths': [1, 1, 1, 1],\n",
    "        'use_invo_stages': (True, True, True, True)\n",
    "    },\n",
    "     {\n",
    "        'name': 'Mamba-Convolution-B0-wider',\n",
    "        'mixer_type': 'Mamba',\n",
    "        'stem_type': 'Convolution',\n",
    "        'backbone_variant': 'mit_b0', # Still based on B0 structure\n",
    "        'embed_dims': [32, 64, 128, 256], # Example of a wider variant\n",
    "        'depths': [1, 1, 1, 1],\n",
    "        'use_invo_stages': (False, False, False, False)\n",
    "    },\n",
    "]\n",
    "\n",
    "print(model_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9647a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def _format_list(vals):\n",
    "    # pipe-separated with 4-decimal precision\n",
    "    return \"[\" + \"|\".join(f\"{float(v):.4f}\" for v in vals) + \"]\"\n",
    "\n",
    "def _flatten_cm(cm):\n",
    "    return \"[\" + \"|\".join(str(int(x)) for x in cm.flatten().tolist()) + \"]\"\n",
    "\n",
    "def train_model_for_config(\n",
    "    config,\n",
    "    dataset_train,\n",
    "    dataset_val,\n",
    "    device=\"cuda\",\n",
    "    epochs_default=50,\n",
    "    batch_size_default=30,\n",
    "    num_classes=2,\n",
    "    base_run_dir=\"runs\",\n",
    "    base_weight_dir=\"weights\",\n",
    "    save_every=5,              # e.g., 10 or None\n",
    "    es_patience_default=10\n",
    "):\n",
    "    name = config['name']\n",
    "    run_dir = os.path.join(base_run_dir, name)\n",
    "    weight_dir = os.path.join(base_weight_dir, name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    os.makedirs(weight_dir, exist_ok=True)\n",
    "\n",
    "    # Build loaders (allow config overrides)\n",
    "    epochs = config.get(\"epochs\", epochs_default)\n",
    "    batch_size = config.get(\"batch_size\", batch_size_default)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(dataset_val,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build model\n",
    "    in_chans = dataset_train[0][0].shape[0]\n",
    "    model = SegFormer(\n",
    "        num_classes=num_classes,\n",
    "        variant=config['backbone_variant'],\n",
    "        drop_path_rate=0.1,\n",
    "        in_chans=in_chans,\n",
    "        embed_dims=config['embed_dims'],\n",
    "        depths=config['depths'],\n",
    "        use_invo_stages=config['use_invo_stages']\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer & scheduler\n",
    "    optimizer = build_optimizer(model, config.get(\"optimizer\"))\n",
    "    scheduler = build_scheduler(optimizer, config.get(\"scheduler\"))\n",
    "\n",
    "    # Criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # TensorBoard writer\n",
    "    writer = SummaryWriter(run_dir)\n",
    "\n",
    "    # Optional: computational analysis once (safe formatting)\n",
    "    try:\n",
    "        computational_metrics = analyze_model(model, input_size=(1, in_chans, 256, 256), device=device)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] analyze_model failed: {e}\")\n",
    "        computational_metrics = {}\n",
    "    # Log static compute metrics if present\n",
    "    if computational_metrics:\n",
    "        if 'params' in computational_metrics:       writer.add_scalar(\"Computational/Params\", computational_metrics['params'], 0)\n",
    "        if 'macs' in computational_metrics:         writer.add_scalar(\"Computational/MACs_M\", computational_metrics['macs'], 0)\n",
    "        if 'flops' in computational_metrics:        writer.add_scalar(\"Computational/FLOPs_M\", computational_metrics['flops'], 0)\n",
    "        if 'avg_inference_time_ms' in computational_metrics:\n",
    "            writer.add_scalar(\"Computational/AvgInference_ms\", computational_metrics['avg_inference_time_ms'], 0)\n",
    "\n",
    "    # Text log\n",
    "    log_path = os.path.join(weight_dir, \"training_log.txt\")\n",
    "    if not os.path.exists(log_path):\n",
    "        with open(log_path, \"w\") as f:\n",
    "            f.write(\"epoch,train_loss,val_pixel_acc,val_mIoU,val_dice,val_precision,val_recall,lr,per_class_iou[],per_class_dice[],confusion_matrix_flat\\n\")\n",
    "\n",
    "    # Early stopping\n",
    "    es_cfg = config.get(\"early_stopping\", {\"monitor\": \"val_mIoU\", \"patience\": es_patience_default})\n",
    "    es_patience = es_cfg.get(\"patience\", es_patience_default)\n",
    "    early_stopper = EarlyStopping(patience=es_patience, mode='max', min_delta=0.0)\n",
    "\n",
    "    best_iou = -1.0\n",
    "    best_epoch = -1\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # --- Train ---\n",
    "        train_loss = train_epoch(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        # --- Validate ---\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                preds  = torch.argmax(logits, dim=1)\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_labels.append(y.cpu().numpy())\n",
    "\n",
    "        y_true = np.concatenate(all_labels, axis=None)\n",
    "        y_pred = np.concatenate(all_preds, axis=None)\n",
    "        metrics = segmentation_metrics(y_true, y_pred, num_classes=num_classes)\n",
    "\n",
    "        val_acc   = float(metrics[\"pixel_acc\"])\n",
    "        val_miou  = float(metrics[\"mean_iou\"])\n",
    "        val_dice  = float(metrics[\"mean_dice\"])\n",
    "        val_prec  = float(metrics[\"precision\"])\n",
    "        val_rec   = float(metrics[\"recall\"])\n",
    "        cls_iou   = metrics[\"per_class_iou\"]\n",
    "        cls_dice  = metrics[\"per_class_dice\"]\n",
    "        cm        = metrics[\"confusion_matrix\"]\n",
    "\n",
    "        # --- LR & Scheduler ---\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if scheduler is not None:\n",
    "            # ReduceLROnPlateau expects a value; we monitor mIoU\n",
    "            scheduler.step(val_miou)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # --- TensorBoard ---\n",
    "        writer.add_scalar(\"Loss/train\",    train_loss, epoch)\n",
    "        writer.add_scalar(\"Val/PixelAcc\",  val_acc,    epoch)\n",
    "        writer.add_scalar(\"Val/mIoU\",      val_miou,   epoch)\n",
    "        writer.add_scalar(\"Val/Dice\",      val_dice,   epoch)\n",
    "        writer.add_scalar(\"Val/Precision\", val_prec,   epoch)\n",
    "        writer.add_scalar(\"Val/Recall\",    val_rec,    epoch)\n",
    "        writer.add_scalar(\"LR/lr\",         current_lr, epoch)\n",
    "\n",
    "        # --- Text log (CSV line) ---\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(f\"{epoch},{train_loss:.6f},{val_acc:.6f},{val_miou:.6f},{val_dice:.6f},{val_prec:.6f},{val_rec:.6f},{current_lr:.8e},{_format_list(cls_iou)},{_format_list(cls_dice)},{_flatten_cm(cm)}\\n\")\n",
    "\n",
    "        # --- Checkpointing ---\n",
    "        if val_miou > best_iou:\n",
    "            best_iou = val_miou\n",
    "            best_epoch = epoch\n",
    "            best_ckpt_path = os.path.join(weight_dir, \"best_model.pth\")\n",
    "            torch.save(model.state_dict(), best_ckpt_path)\n",
    "            print(f\"[{name}] ✔ New best mIoU={best_iou:.4f} at epoch {epoch} → saved {best_ckpt_path}\")\n",
    "\n",
    "        if save_every is not None and epoch % save_every == 0:\n",
    "            ep_path = os.path.join(weight_dir, f\"epoch_{epoch:03d}.pth\")\n",
    "            torch.save(model.state_dict(), ep_path)\n",
    "\n",
    "        # --- Early stopping ---\n",
    "        if early_stopper.step(val_miou):\n",
    "            print(f\"[{name}] ⏹ Early stopping at epoch {epoch} (no improvement for {es_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    # Final summary in log file\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(f\"BEST_EPOCH={best_epoch}\\nBEST_mIoU={best_iou:.6f}\\nTOTAL_TIME_SEC={total_time:.2f}\\n\")\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    # Print run summary\n",
    "    print(f\"[{name}] Finished. Best mIoU={best_iou:.4f} at epoch {best_epoch}. Log: {log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c158c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing configuration: Mamba-Involution-B0-default ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 16, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 16, 128, 128]         5,795\n",
      "│    │    └─MiTStage: 3-2                          [1, 32, 64, 64]           19,057\n",
      "│    │    └─MiTStage: 3-3                          [1, 64, 32, 32]           68,441\n",
      "│    │    └─MiTStage: 3-4                          [1, 128, 16, 16]          258,217\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        2,304\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          4,352\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          8,448\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          16,640\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 597,016\n",
      "Trainable params: 597,016\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.57\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 149.38\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 154.01\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.6161 at epoch 1 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:46<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.6280 at epoch 2 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:37<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.6581 at epoch 3 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:35<00:00,  1.43s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.7267 at epoch 5 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9447 at epoch 6 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9452 at epoch 7 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:36<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9665 at epoch 8 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9816 at epoch 9 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9845 at epoch 10 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9858 at epoch 12 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9903 at epoch 13 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:35<00:00,  1.43s/it]\n",
      "100%|██████████| 67/67 [01:46<00:00,  1.59s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n",
      "100%|██████████| 67/67 [01:35<00:00,  1.42s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9921 at epoch 20 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] ✔ New best mIoU=0.9922 at epoch 23 → saved weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:35<00:00,  1.42s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n",
      "100%|██████████| 67/67 [01:46<00:00,  1.59s/it]\n",
      "100%|██████████| 67/67 [01:50<00:00,  1.64s/it]\n",
      "100%|██████████| 67/67 [01:35<00:00,  1.42s/it]\n",
      "100%|██████████| 67/67 [01:50<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-default] Finished. Best mIoU=0.9922 at epoch 23. Log: weights/NIRD_Config/Mamba-Involution-B0-default/training_log.txt\n",
      "\n",
      "=== Processing configuration: Mamba-Convolution-B0-default ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 16, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 16, 128, 128]         7,136\n",
      "│    │    └─MiTStage: 3-2                          [1, 32, 64, 64]           23,008\n",
      "│    │    └─MiTStage: 3-3                          [1, 64, 32, 32]           84,416\n",
      "│    │    └─MiTStage: 3-4                          [1, 128, 16, 16]          322,432\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        2,304\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          4,352\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          8,448\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          16,640\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 682,498\n",
      "Trainable params: 682,498\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.64\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 147.32\n",
      "Params size (MB): 2.08\n",
      "Estimated Total Size (MB): 152.29\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9734 at epoch 1 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9814 at epoch 2 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:56<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9862 at epoch 3 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9890 at epoch 4 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9897 at epoch 5 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9901 at epoch 6 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9902 at epoch 7 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9913 at epoch 8 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9922 at epoch 9 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9928 at epoch 10 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9932 at epoch 11 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9949 at epoch 12 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:49<00:00,  1.63s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:32<00:00,  1.38s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9952 at epoch 17 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:32<00:00,  1.38s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9953 at epoch 19 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:32<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9956 at epoch 20 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9961 at epoch 22 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9965 at epoch 24 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [01:32<00:00,  1.38s/it]\n",
      "100%|██████████| 67/67 [01:45<00:00,  1.58s/it]\n",
      "100%|██████████| 67/67 [01:45<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] ✔ New best mIoU=0.9968 at epoch 28 → saved weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:45<00:00,  1.57s/it]\n",
      "100%|██████████| 67/67 [01:32<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-default] Finished. Best mIoU=0.9968 at epoch 28. Log: weights/NIRD_Config/Mamba-Convolution-B0-default/training_log.txt\n",
      "\n",
      "=== Processing configuration: Mamba-Involution-B0-shallow ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 16, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 16, 128, 128]         5,795\n",
      "│    │    └─MiTStage: 3-2                          [1, 32, 64, 64]           19,057\n",
      "│    │    └─MiTStage: 3-3                          [1, 64, 32, 32]           68,441\n",
      "│    │    └─MiTStage: 3-4                          [1, 128, 16, 16]          258,217\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        2,304\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          4,352\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          8,448\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          16,640\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 597,016\n",
      "Trainable params: 597,016\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.57\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 149.38\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 154.01\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9245 at epoch 1 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9652 at epoch 2 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9684 at epoch 3 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9863 at epoch 4 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9902 at epoch 5 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9907 at epoch 6 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:48<00:00,  1.62s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9912 at epoch 8 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9920 at epoch 9 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.42s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n",
      "100%|██████████| 67/67 [01:44<00:00,  1.56s/it]\n",
      "100%|██████████| 67/67 [01:45<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9927 at epoch 14 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9933 at epoch 15 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:47<00:00,  1.60s/it]\n",
      "100%|██████████| 67/67 [01:46<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9935 at epoch 17 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9939 at epoch 20 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9940 at epoch 21 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [02:01<00:00,  1.81s/it]\n",
      "100%|██████████| 67/67 [01:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9941 at epoch 24 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n",
      "100%|██████████| 67/67 [01:44<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9943 at epoch 26 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:34<00:00,  1.40s/it]\n",
      "100%|██████████| 67/67 [01:33<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9945 at epoch 28 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:44<00:00,  1.55s/it]\n",
      "100%|██████████| 67/67 [01:47<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-shallow] ✔ New best mIoU=0.9948 at epoch 30 → saved weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n",
      "[Mamba-Involution-B0-shallow] Finished. Best mIoU=0.9948 at epoch 30. Log: weights/NIRD_Config/Mamba-Involution-B0-shallow/training_log.txt\n",
      "\n",
      "=== Processing configuration: Mamba-Involution-B0-deep ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 16, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 16, 128, 128]         11,315\n",
      "│    │    └─MiTStage: 3-2                          [1, 32, 64, 64]           37,393\n",
      "│    │    └─MiTStage: 3-3                          [1, 64, 32, 32]           134,297\n",
      "│    │    └─MiTStage: 3-4                          [1, 128, 16, 16]          506,665\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        2,304\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          4,352\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          8,448\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          16,640\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 935,176\n",
      "Trainable params: 935,176\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.57\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 176.91\n",
      "Params size (MB): 2.44\n",
      "Estimated Total Size (MB): 182.23\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.8826 at epoch 1 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9633 at epoch 2 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9754 at epoch 3 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:52<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9777 at epoch 4 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9813 at epoch 5 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9842 at epoch 6 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9850 at epoch 7 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9861 at epoch 9 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.69s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [01:52<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9874 at epoch 12 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9881 at epoch 13 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9914 at epoch 14 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [01:52<00:00,  1.68s/it]\n",
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9914 at epoch 20 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:52<00:00,  1.67s/it]\n",
      "100%|██████████| 67/67 [02:07<00:00,  1.90s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n",
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n",
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n",
      "100%|██████████| 67/67 [01:41<00:00,  1.52s/it]\n",
      "100%|██████████| 67/67 [01:42<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9917 at epoch 29 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:52<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-deep] ✔ New best mIoU=0.9918 at epoch 30 → saved weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n",
      "[Mamba-Involution-B0-deep] Finished. Best mIoU=0.9918 at epoch 30. Log: weights/NIRD_Config/Mamba-Involution-B0-deep/training_log.txt\n",
      "\n",
      "=== Processing configuration: Mamba-Involution-B0-wider ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 32, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 32, 128, 128]         18,835\n",
      "│    │    └─MiTStage: 3-2                          [1, 64, 64, 64]           68,441\n",
      "│    │    └─MiTStage: 3-3                          [1, 128, 32, 32]          258,217\n",
      "│    │    └─MiTStage: 3-4                          [1, 256, 16, 16]          1,001,801\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        4,352\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          8,448\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          16,640\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          33,024\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 1,623,520\n",
      "Trainable params: 1,623,520\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.66\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 185.00\n",
      "Params size (MB): 4.11\n",
      "Estimated Total Size (MB): 191.99\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:18<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9029 at epoch 1 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9102 at epoch 3 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n",
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9668 at epoch 5 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [02:03<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9672 at epoch 7 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n",
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9771 at epoch 10 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:15<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9895 at epoch 11 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:05<00:00,  1.87s/it]\n",
      "100%|██████████| 67/67 [01:41<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9917 at epoch 13 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.51s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9923 at epoch 15 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:51<00:00,  1.66s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9930 at epoch 17 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:51<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9931 at epoch 18 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:17<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9931 at epoch 19 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n",
      "100%|██████████| 67/67 [01:54<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9936 at epoch 21 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:53<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9943 at epoch 22 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:51<00:00,  1.66s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] ✔ New best mIoU=0.9949 at epoch 25 → saved weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:40<00:00,  1.49s/it]\n",
      "100%|██████████| 67/67 [01:40<00:00,  1.50s/it]\n",
      "100%|██████████| 67/67 [01:49<00:00,  1.64s/it]\n",
      "100%|██████████| 67/67 [01:52<00:00,  1.68s/it]\n",
      "100%|██████████| 67/67 [01:53<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Involution-B0-wider] Finished. Best mIoU=0.9949 at epoch 25. Log: weights/NIRD_Config/Mamba-Involution-B0-wider/training_log.txt\n",
      "\n",
      "=== Processing configuration: Mamba-Convolution-B0-wider ===\n",
      "[INFO] Using device: cuda\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "SegFormer                                          [1, 2, 256, 256]          --\n",
      "├─MixVisionTransformer: 1-1                        [1, 32, 128, 128]         --\n",
      "│    └─ModuleList: 2-1                             --                        --\n",
      "│    │    └─MiTStage: 3-1                          [1, 32, 128, 128]         21,568\n",
      "│    │    └─MiTStage: 3-2                          [1, 64, 64, 64]           84,416\n",
      "│    │    └─MiTStage: 3-3                          [1, 128, 32, 32]          322,432\n",
      "│    │    └─MiTStage: 3-4                          [1, 256, 16, 16]          1,259,264\n",
      "├─SegFormerHead: 1-2                               [1, 2, 128, 128]          --\n",
      "│    └─ModuleList: 2-2                             --                        --\n",
      "│    │    └─Sequential: 3-5                        [1, 128, 128, 128]        4,352\n",
      "│    │    └─Sequential: 3-6                        [1, 128, 64, 64]          8,448\n",
      "│    │    └─Sequential: 3-7                        [1, 128, 32, 32]          16,640\n",
      "│    │    └─Sequential: 3-8                        [1, 128, 16, 16]          33,024\n",
      "│    └─Sequential: 2-3                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-9                            [1, 128, 128, 128]        65,536\n",
      "│    │    └─BatchNorm2d: 3-10                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-11                             [1, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-12                           [1, 128, 128, 128]        147,456\n",
      "│    │    └─BatchNorm2d: 3-13                      [1, 128, 128, 128]        256\n",
      "│    │    └─ReLU: 3-14                             [1, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-4                                 [1, 2, 128, 128]          258\n",
      "====================================================================================================\n",
      "Total params: 1,963,906\n",
      "Trainable params: 1,963,906\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.90\n",
      "====================================================================================================\n",
      "Input size (MB): 2.88\n",
      "Forward/backward pass size (MB): 182.71\n",
      "Params size (MB): 5.47\n",
      "Estimated Total Size (MB): 191.07\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9795 at epoch 1 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:16<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9870 at epoch 2 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9884 at epoch 3 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9905 at epoch 4 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9921 at epoch 5 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:37<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9928 at epoch 6 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9935 at epoch 7 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:58<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9939 at epoch 8 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:00<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9945 at epoch 9 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9945 at epoch 10 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [02:25<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9957 at epoch 11 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n",
      "100%|██████████| 67/67 [01:51<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9959 at epoch 13 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:51<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9962 at epoch 14 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9965 at epoch 15 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n",
      "100%|██████████| 67/67 [01:39<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9966 at epoch 17 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.47s/it]\n",
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9969 at epoch 19 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.47s/it]\n",
      "100%|██████████| 67/67 [01:58<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9970 at epoch 21 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9973 at epoch 22 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9976 at epoch 23 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:38<00:00,  1.47s/it]\n",
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9977 at epoch 25 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9980 at epoch 26 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n",
      "100%|██████████| 67/67 [01:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9981 at epoch 28 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] ✔ New best mIoU=0.9982 at epoch 29 → saved weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mamba-Convolution-B0-wider] Finished. Best mIoU=0.9982 at epoch 29. Log: weights/NIRD_Config/Mamba-Convolution-B0-wider/training_log.txt\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Default knobs (used if a config doesn’t specify them)\n",
    "DEFAULTS = {\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 30,\n",
    "    \"optimizer\": {\"name\": \"AdamW\", \"lr\": 1e-4, \"weight_decay\": 1e-4},\n",
    "    \"scheduler\": {\"name\": \"ReduceLROnPlateau\", \"factor\": 0.5, \"patience\": 5, \"min_lr\": 1e-7},\n",
    "    \"early_stopping\": {\"patience\": 12},\n",
    "    \"save_every\": 5,\n",
    "}\n",
    "\n",
    "for config in model_configs:\n",
    "    print(f\"\\n=== Processing configuration: {config['name']} ===\")\n",
    "\n",
    "    # Merge defaults with per-config overrides\n",
    "    merged_cfg = {**DEFAULTS, **config}\n",
    "\n",
    "    train_model_for_config(\n",
    "        config=merged_cfg,\n",
    "        dataset_train=dataset_train,\n",
    "        dataset_val=dataset_val,\n",
    "        device=DEVICE,\n",
    "        epochs_default=merged_cfg[\"epochs\"],\n",
    "        batch_size_default=merged_cfg[\"batch_size\"],\n",
    "        num_classes=NUM_CLASSES,\n",
    "        base_run_dir=\"runs\",\n",
    "        base_weight_dir=WEIGHT_DIR,\n",
    "        save_every=merged_cfg.get(\"save_every\", None),\n",
    "        es_patience_default=merged_cfg[\"early_stopping\"][\"patience\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51032377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Evaluation Pipeline for SegFormer-Mamba Models\n",
    "# This script loads best models, evaluates metrics, collects computational stats,\n",
    "# and generates comparison tables + visualizations.\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    jaccard_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Ensure reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Directories\n",
    "RESULTS_DIR = \"results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"plots\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"visualizations\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94dbf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_as_csv_md(results, csv_path, md_path):\n",
    "    \"\"\"\n",
    "    Save evaluation results to CSV and Markdown table.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Build Markdown table\n",
    "    with open(md_path, \"w\") as f:\n",
    "        f.write(df.to_markdown(index=False))\n",
    "\n",
    "    print(f\"[INFO] Saved results → {csv_path}, {md_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f26a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from thop import profile\n",
    "from torchinfo import summary\n",
    "\n",
    "def collect_computational_metrics(model, input_size=(1, 11, 256, 256), device=\"cuda\"):\n",
    "    \"\"\"Collect Params, FLOPs, Inference Time for a model.\"\"\"\n",
    "    device = device if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    dummy_input = torch.randn(*input_size).to(device)\n",
    "\n",
    "    # --- Params & FLOPs ---\n",
    "    try:\n",
    "        macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "        flops = 2 * macs   # 1 MAC = 2 FLOPs\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] thop profiling failed: {e}\")\n",
    "        macs, params, flops = 0, 0, 0\n",
    "\n",
    "    # --- Inference time ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):  # warm-up\n",
    "            _ = model(dummy_input)\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for _ in range(20):\n",
    "            _ = model(dummy_input)\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "    avg_time = (end - start) / 20 * 1000  # ms per sample\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"macs\": macs / 1e6,\n",
    "        \"flops\": flops / 1e6,\n",
    "        \"inference_ms\": avg_time\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0daa8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def segmentation_metrics(y_true, y_pred, num_classes=2):\n",
    "    \"\"\"Compute IoU, Dice, Precision, Recall, Pixel Accuracy for segmentation.\"\"\"\n",
    "    y_true = y_true.ravel()\n",
    "    y_pred = y_pred.ravel()\n",
    "\n",
    "    labels = list(range(num_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    per_class_iou  = jaccard_score (y_true, y_pred, average=None, labels=labels, zero_division=0)\n",
    "    mean_iou       = jaccard_score (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    per_class_dice = f1_score      (y_true, y_pred, average=None, labels=labels, zero_division=0)\n",
    "    mean_dice      = f1_score      (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    precision      = precision_score(y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    recall         = recall_score   (y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    pixel_acc      = accuracy_score (y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"pixel_acc\": pixel_acc,\n",
    "        \"mean_iou\": mean_iou,\n",
    "        \"mean_dice\": mean_dice,\n",
    "        \"per_class_iou\": per_class_iou,\n",
    "        \"per_class_dice\": per_class_dice,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8683f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def visualize_samples(model, dataset, device, config_name, out_dir=\"results/visualizations\", num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize RGB (from optical bands), Ground Truth, Prediction, and Overlay.\n",
    "    Saves PNGs in results/visualizations/<config_name>/.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    os.makedirs(os.path.join(out_dir, config_name), exist_ok=True)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # --- Pick a random sample ---\n",
    "        idx = random.randint(0, len(dataset)-1)\n",
    "        x, y = dataset[idx]\n",
    "\n",
    "        # Extract RGB correctly (optical channels: 2,3,4)\n",
    "        rgb = x[2:5].numpy().transpose(1, 2, 0)  \n",
    "        rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-6)\n",
    "\n",
    "        # --- Model prediction ---\n",
    "        with torch.no_grad():\n",
    "            inp = x.unsqueeze(0).to(device)\n",
    "            logits = model(inp)\n",
    "            pred = torch.argmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        gt = y.numpy()\n",
    "\n",
    "        # --- Create figure ---\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "        axs[0].imshow(rgb)\n",
    "        axs[0].set_title(\"RGB Image\")\n",
    "        axs[1].imshow(gt, cmap=\"nipy_spectral\")\n",
    "        axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(pred, cmap=\"nipy_spectral\")\n",
    "        axs[2].set_title(\"Prediction\")\n",
    "        axs[3].imshow(rgb)\n",
    "        axs[3].imshow(pred, cmap=\"nipy_spectral\", alpha=0.5)\n",
    "        axs[3].set_title(\"Overlay\")\n",
    "        for ax in axs:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        # --- Save figure ---\n",
    "        save_path = os.path.join(out_dir, config_name, f\"sample_{i+1}.png\")\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf4db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def evaluate_model(model, dataloader, device, num_classes=2):\n",
    "    \"\"\"\n",
    "    Run evaluation on a dataset and compute segmentation metrics.\n",
    "    Returns a dict with accuracy, IoU, Dice, Precision, Recall.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_labels, axis=None)\n",
    "    y_pred = np.concatenate(all_preds, axis=None)\n",
    "\n",
    "    return segmentation_metrics(y_true, y_pred, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a08a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def run_full_evaluation(model_configs, dataset_val, device=\"cuda\", num_classes=2):\n",
    "    \"\"\"\n",
    "    Loop through all model configs, load best weights, \n",
    "    evaluate metrics, collect compute stats, and visualize.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    val_loader = DataLoader(dataset_val, batch_size=30, shuffle=False)\n",
    "\n",
    "    for config in model_configs:\n",
    "        name = config[\"name\"]\n",
    "        print(f\"\\n=== Evaluating {name} ===\")\n",
    "\n",
    "        # Paths\n",
    "        weight_dir = os.path.join(\"weights\",\"NIRD_Config\", name)\n",
    "        best_ckpt = os.path.join(weight_dir, \"best_model.pth\")\n",
    "\n",
    "        if not os.path.exists(best_ckpt):\n",
    "            print(f\"[WARN] Best model not found for {name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Build model ---\n",
    "        in_chans = dataset_val[0][0].shape[0]\n",
    "        model = SegFormer(\n",
    "            num_classes=num_classes,\n",
    "            variant=config[\"backbone_variant\"],\n",
    "            in_chans=in_chans,\n",
    "            embed_dims=config[\"embed_dims\"],\n",
    "            depths=config[\"depths\"],\n",
    "            use_invo_stages=config[\"use_invo_stages\"]\n",
    "        ).to(device)\n",
    "\n",
    "        # Load weights\n",
    "        state_dict = torch.load(best_ckpt, map_location=device)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"[INFO] Loaded best model from {best_ckpt}\")\n",
    "\n",
    "        # --- Computational metrics ---\n",
    "        comp_stats = collect_computational_metrics(model, input_size=(1, in_chans, 256, 256), device=device)\n",
    "\n",
    "        # --- Evaluation metrics ---\n",
    "        eval_stats = evaluate_model(model, val_loader, device, num_classes=num_classes)\n",
    "\n",
    "        # --- Combine results ---\n",
    "        result = {\n",
    "            \"Model\": name,\n",
    "            \"Params(M)\": comp_stats[\"params\"] / 1e6,\n",
    "            \"FLOPs(M)\": comp_stats[\"flops\"],\n",
    "            \"InferTime(ms)\": comp_stats[\"inference_ms\"],\n",
    "            \"mIoU\": eval_stats[\"mean_iou\"],\n",
    "            \"Dice\": eval_stats[\"mean_dice\"],\n",
    "            \"Precision\": eval_stats[\"precision\"],\n",
    "            \"Recall\": eval_stats[\"recall\"],\n",
    "            \"PixelAcc\": eval_stats[\"pixel_acc\"],\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        # --- Save visualizations ---\n",
    "        visualize_samples(model, dataset_val, device, config_name=name, out_dir=\"results/visualizations\")\n",
    "\n",
    "    # --- Save results table ---\n",
    "    csv_path = os.path.join(\"results\", \"metrics.csv\")\n",
    "    md_path  = os.path.join(\"results\", \"metrics.md\")\n",
    "    df = save_results_as_csv_md(results, csv_path, md_path)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b188f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def plot_results_table(df, out_dir=\"results/plots\"):\n",
    "    \"\"\"\n",
    "    Generate bar plots comparing models on accuracy and efficiency metrics.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Metrics groups\n",
    "    accuracy_metrics = [\"mIoU\", \"Dice\", \"Precision\", \"Recall\", \"PixelAcc\"]\n",
    "    efficiency_metrics = [\"Params(M)\", \"FLOPs(M)\", \"InferTime(ms)\"]\n",
    "\n",
    "    # --- Accuracy plots ---\n",
    "    for metric in accuracy_metrics:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(df[\"Model\"], df[metric], color=\"skyblue\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f\"Comparison of {metric}\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(out_dir, f\"{metric}_comparison.png\")\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"[INFO] Saved {metric} plot → {save_path}\")\n",
    "\n",
    "    # --- Efficiency plots ---\n",
    "    for metric in efficiency_metrics:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(df[\"Model\"], df[metric], color=\"salmon\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f\"Comparison of {metric}\")\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(out_dir, f\"{metric}_comparison.png\")\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"[INFO] Saved {metric} plot → {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0f3383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Mamba-Involution-B0-default ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Involution-B0-default/best_model.pth\n",
      "\n",
      "=== Evaluating Mamba-Convolution-B0-default ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Convolution-B0-default/best_model.pth\n",
      "\n",
      "=== Evaluating Mamba-Involution-B0-shallow ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Involution-B0-shallow/best_model.pth\n",
      "\n",
      "=== Evaluating Mamba-Involution-B0-deep ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Involution-B0-deep/best_model.pth\n",
      "\n",
      "=== Evaluating Mamba-Involution-B0-wider ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Involution-B0-wider/best_model.pth\n",
      "\n",
      "=== Evaluating Mamba-Convolution-B0-wider ===\n",
      "[INFO] Loaded best model from weights/NIRD_Config/Mamba-Convolution-B0-wider/best_model.pth\n",
      "[INFO] Saved results → results/metrics.csv, results/metrics.md\n",
      "[INFO] Saved mIoU plot → results/plots/mIoU_comparison.png\n",
      "[INFO] Saved Dice plot → results/plots/Dice_comparison.png\n",
      "[INFO] Saved Precision plot → results/plots/Precision_comparison.png\n",
      "[INFO] Saved Recall plot → results/plots/Recall_comparison.png\n",
      "[INFO] Saved PixelAcc plot → results/plots/PixelAcc_comparison.png\n",
      "[INFO] Saved Params(M) plot → results/plots/Params(M)_comparison.png\n",
      "[INFO] Saved FLOPs(M) plot → results/plots/FLOPs(M)_comparison.png\n",
      "[INFO] Saved InferTime(ms) plot → results/plots/InferTime(ms)_comparison.png\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Model                        |   Params(M) |   FLOPs(M) |   InferTime(ms) |     mIoU |     Dice |   Precision |   Recall |   PixelAcc |\n",
       "|:-----------------------------|------------:|-----------:|----------------:|---------:|---------:|------------:|---------:|-----------:|\n",
       "| Mamba-Involution-B0-default  |    0.434136 |    7464.08 |         2.85507 | 0.99231  | 0.996138 |    0.996233 | 0.996043 |   0.996679 |\n",
       "| Mamba-Convolution-B0-default |    0.519618 |    7606.89 |         2.40961 | 0.996676 | 0.998335 |    0.998296 | 0.998374 |   0.998574 |\n",
       "| Mamba-Involution-B0-shallow  |    0.434136 |    7464.08 |         2.81612 | 0.994556 | 0.997269 |    0.997638 | 0.996903 |   0.9977   |\n",
       "| Mamba-Involution-B0-deep     |    0.609416 |    7732.52 |         4.99783 | 0.990888 | 0.99542  |    0.99586  | 0.994985 |   0.995976 |\n",
       "| Mamba-Involution-B0-wider    |    1.02576  |    8448.13 |         2.84063 | 0.994255 | 0.997118 |    0.996884 | 0.997352 |   0.997591 |\n",
       "| Mamba-Convolution-B0-wider   |    1.36615  |    8933.61 |         2.45694 | 0.99821  | 0.999104 |    0.999103 | 0.999104 |   0.999222 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 2   # adjust if more classes\n",
    "\n",
    "# Run full evaluation across all configs\n",
    "df_results = run_full_evaluation(\n",
    "    model_configs=model_configs,\n",
    "    dataset_val=dataset_test,\n",
    "    device=DEVICE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plot_results_table(df_results, out_dir=\"results/plots\")\n",
    "\n",
    "# Show Markdown table inline\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(df_results.to_markdown(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bca732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved plot → results/plots/train_loss_comparison.png\n",
      "[INFO] Saved plot → results/plots/val_loss_comparison.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6468/3208247965.py:35: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(fontsize=9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved plot → results/plots/val_mIoU_comparison.png\n",
      "[INFO] Saved plot → results/plots/val_dice_comparison.png\n",
      "[INFO] Saved plot → results/plots/val_pixel_acc_comparison.png\n",
      "[INFO] Saved plot → results/plots/val_precision_comparison.png\n",
      "[INFO] Saved plot → results/plots/val_recall_comparison.png\n",
      "[INFO] Saved summary → results/summary.csv, results/summary.md\n",
      "                          Model  BestEpoch  TrainLoss ValLoss  Best_mIoU  \\\n",
      "0      Mamba-Involution-B0-deep         30   0.018755    None   0.991763   \n",
      "1     Mamba-Involution-B0-wider         25   0.011387    None   0.994926   \n",
      "2  Mamba-Convolution-B0-default         28   0.005104    None   0.996816   \n",
      "3    Mamba-Convolution-B0-wider         29   0.002449    None   0.998154   \n",
      "4   Mamba-Involution-B0-default         23   0.021569    None   0.992243   \n",
      "5   Mamba-Involution-B0-shallow         30   0.009784    None   0.994787   \n",
      "\n",
      "   Best_Dice  Best_Acc  Best_Precision  Best_Recall  \n",
      "0   0.995862  0.996509        0.996152     0.995572  \n",
      "1   0.997455  0.997868        0.997375     0.997536  \n",
      "2   0.998405  0.998634        0.998358     0.998452  \n",
      "3   0.999076  0.999273        0.999055     0.999096  \n",
      "4   0.996105  0.996598        0.996167     0.996042  \n",
      "5   0.997386  0.997856        0.997778     0.996995  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_DIR = \"weights/NIRD_Config\"   # parent directory containing all model subfolders\n",
    "OUT_DIR = \"results/plots\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def load_all_logs(base_dir=BASE_DIR):\n",
    "    \"\"\"Load all training_log.txt files under base_dir/*/\"\"\"\n",
    "    logs = {}\n",
    "    for model in os.listdir(base_dir):\n",
    "        log_path = os.path.join(base_dir, model, \"training_log.txt\")\n",
    "        if os.path.exists(log_path):\n",
    "            try:\n",
    "                df = pd.read_csv(log_path)\n",
    "                logs[model] = df\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Could not parse {log_path}: {e}\")\n",
    "    return logs\n",
    "\n",
    "def plot_metric(logs, metric, out_dir=OUT_DIR, ylabel=None):\n",
    "    \"\"\"Plot one metric across all models with bold lines and larger font.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model, df in logs.items():\n",
    "        if metric in df.columns:\n",
    "            plt.plot(\n",
    "                df[\"epoch\"], df[metric],\n",
    "                label=model, linewidth=2\n",
    "            )\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(ylabel or metric, fontsize=12)\n",
    "    plt.title(f\"{metric} Comparison Across Models\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.legend(fontsize=9)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(out_dir, f\"{metric}_comparison.png\")\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Saved plot → {save_path}\")\n",
    "\n",
    "def summarize_best(logs, out_path=\"results/summary.csv\"):\n",
    "    \"\"\"Save best mIoU per model and other final stats into CSV + Markdown.\"\"\"\n",
    "    rows = []\n",
    "    for model, df in logs.items():\n",
    "        if \"val_mIoU\" in df.columns:\n",
    "            best_row = df.loc[df[\"val_mIoU\"].idxmax()]\n",
    "            row = {\n",
    "                \"Model\": model,\n",
    "                \"BestEpoch\": int(best_row[\"epoch\"]),\n",
    "                \"TrainLoss\": best_row[\"train_loss\"] if \"train_loss\" in best_row else None,\n",
    "                \"ValLoss\": best_row[\"val_loss\"] if \"val_loss\" in best_row else None,\n",
    "                \"Best_mIoU\": best_row[\"val_mIoU\"],\n",
    "                \"Best_Dice\": best_row[\"val_dice\"],\n",
    "                \"Best_Acc\": best_row[\"val_pixel_acc\"],\n",
    "                \"Best_Precision\": best_row[\"val_precision\"],\n",
    "                \"Best_Recall\": best_row[\"val_recall\"]\n",
    "            }\n",
    "            rows.append(row)\n",
    "    summary = pd.DataFrame(rows)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    summary.to_csv(out_path, index=False)\n",
    "    md_path = out_path.replace(\".csv\", \".md\")\n",
    "    summary.to_markdown(md_path, index=False)\n",
    "    print(f\"[INFO] Saved summary → {out_path}, {md_path}\")\n",
    "    return summary\n",
    "\n",
    "# --- Run everything ---\n",
    "logs = load_all_logs(BASE_DIR)\n",
    "\n",
    "metrics = {\n",
    "    \"train_loss\": \"Training Loss\",\n",
    "    \"val_loss\": \"Validation Loss\",          # 🔹 added\n",
    "    \"val_mIoU\": \"Validation mIoU\",\n",
    "    \"val_dice\": \"Validation Dice\",\n",
    "    \"val_pixel_acc\": \"Validation Pixel Accuracy\",\n",
    "    \"val_precision\": \"Validation Precision\",\n",
    "    \"val_recall\": \"Validation Recall\"\n",
    "}\n",
    "for m, label in metrics.items():\n",
    "    plot_metric(logs, m, ylabel=label)\n",
    "\n",
    "summary_df = summarize_best(logs)\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf793a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
